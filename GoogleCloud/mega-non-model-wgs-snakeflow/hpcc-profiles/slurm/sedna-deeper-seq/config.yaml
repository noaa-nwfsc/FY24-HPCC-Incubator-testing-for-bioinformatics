cluster:
  mkdir -p results/slurm_logs/{rule} &&
  sbatch
    --exclude=node[29-36]
    --cpus-per-task={threads}
    --mem={resources.mem_mb}
    --time={resources.time}
    --job-name=smk-{rule}-{wildcards}
    --output=results/slurm_logs/{rule}/{rule}-{wildcards}-%j.out
    --error=results/slurm_logs/{rule}/{rule}-{wildcards}-%j.err
    --parsable
default-resources:
  - time="08:00:00"
  - mem_mb=4800
restart-times: 0
max-jobs-per-second: 10
max-status-checks-per-second: 50
local-cores: 1
latency-wait: 60
cores: 600
jobs: 1200
keep-going: True
rerun-incomplete: True
printshellcmds: True
use-conda: True
cluster-status: status-sacct-robust.sh
cluster-cancel: scancel
cluster-cancel-nargs: 1000

set-threads:
  map_reads: 20
  trim_reads_pe: 5 
set-resources:
  map_reads:
    mem_mb: 94000
    time: "7-00:00:00"
  mark_duplicates:
    mem_mb: 47000
    time: "7-00:00:00"
  trim_reads_pe:
    mem_mb: 23500
    time: "7-00:00:00"

